# Report

Firstly, I implemented a company name processing pipeline to normalize variations in names, such as abbreviations and formatting, significantly improving the accuracy of the matching process. The pipeline includes several steps: removing punctuation, mapping abbreviations to full terms, stemming words, and filtering out stop words. For instance, using a keyword processor, abbreviations like "inc" are mapped to "incorporated," which reduces mismatches due to minor typographical variations. Stemming also enhances matching quality, allowing terms like “Computer” and “Computing” to align more closely in similarity scoring.

To achieve accurate and efficient fuzzy matching, I ultimately employed a K-Nearest Neighbors (KNN) approach, with TF-IDF vector embeddings and cosine similarity as the distance metric. TF-IDF captures term importance in context, effectively transforming each company name into a vector embedding that reflects character n-gram frequencies, enhancing match accuracy. Cosine similarity works well with these embeddings, identifying similarities and providing reliable rankings even for longer or complex names, such as accurately matching "Meta Platforms, Inc." with the related shorter name "Meta." Compared to methods, which I tried earlier, like the BK-tree with Levenshtein distance, which penalized longer names disproportionately, or the Ratcliff/Obershelp algorithm, which struggled with word reordering, the TF-IDF and KNN-based solution is faster and more scalable, especially suited for larger datasets due to its efficient retrieval capabilities. Limitations include potential inaccuracies in cases where character-based embeddings alone may not capture deeper semantic relationships; however, pre-processing steps like abbreviation normalization alleviate these challenges. Performance-wise, the model effectively returned correct matches, as seen with 'Apple Inc.', which matched closely with variations like "Apple Computer Inc." and "Computer Inc Apple."
